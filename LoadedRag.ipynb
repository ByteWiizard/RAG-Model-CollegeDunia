{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector database loaded from models\n"
     ]
    }
   ],
   "source": [
    "persist_directory = \"models\"\n",
    "embedding_function = OllamaEmbeddings(model=\"nomic-embed-text\", show_progress=True)\n",
    "\n",
    "# Load the persisted vector store from the specified directory\n",
    "vector_db = Chroma(\n",
    "    persist_directory=persist_directory,  # Loading from the persistence directory\n",
    "    embedding_function=embedding_function,\n",
    "    collection_name=\"local-rag\"\n",
    ")\n",
    "\n",
    "print(f\"Vector database loaded from {persist_directory}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the language model\n",
    "local_model = \"mistral\"\n",
    "llm = ChatOllama(model=local_model)\n",
    "\n",
    "# Create a prompt template for generating multiple query variations\n",
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are an AI language model assistant. Your task is to generate five\n",
    "    different versions of the given user question to retrieve relevant documents from\n",
    "    a vector database. By generating multiple perspectives on the user question, your\n",
    "    goal is to help the user overcome some of the limitations of the distance-based\n",
    "    similarity search. Provide these alternative questions separated by newlines.\n",
    "    Original question: {question}\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Retrieve relevant chunks with embeddings applied only at this stage\n",
    "retriever = vector_db.as_retriever(\n",
    "    search_type=\"similarity\",  # You can also use other search types such as \"mmr\"\n",
    "    embedding=OllamaEmbeddings(model=\"nomic-embed-text\", show_progress=True)\n",
    ")\n",
    "\n",
    "# Use multi-query retriever to generate multiple query variations\n",
    "multi_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=retriever, \n",
    "    llm=llm,\n",
    "    prompt=QUERY_PROMPT\n",
    ")\n",
    "\n",
    "# Define a prompt template for the final RAG-based answer generation\n",
    "template = \"\"\"Answer the question based ONLY on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final prompt and chain for the RAG system\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "chain = (\n",
    "    {\"context\": multi_retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:04<00:00,  4.72s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.08s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.10s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.19s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.33s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1. For body-worn operation, the device holder should not contain metal and should provide at least the stated separation distance from the body. The mobile device may be transmitting even when you are not making a voice call.\\n\\n2. Always obey all local laws. Your first consideration while driving should be road safety; keep your hands free to operate the vehicle when driving.\\n\\n3. All wireless devices may be susceptible to interference, which could affect performance.\\n\\n4. When using the device, avoid touching electronic components while changing any covers. Store and use the device with any covers attached.\\n\\n5. The device may contain parts that are magnetic. Metallic materials may be attracted to the device, so do not place credit cards or other magnetic stripe cards near the device for extended periods of time, as the cards may be damaged.\\n\\n6. Switch the device off when mobile phone use is not allowed or when it may cause interference or danger, such as in aircraft, hospitals, or restricted areas. Obey all instructions in restricted areas.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What safety precautions should i keep in mind?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CollegeDunia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
